{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf0baab2-4260-4d75-8bae-28f7dd2c695c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "593/593 [==============================] - 182s 305ms/step - loss: 0.6828 - accuracy: 0.7483 - val_loss: 0.3474 - val_accuracy: 0.8794\n",
      "Epoch 2/10\n",
      "593/593 [==============================] - 185s 312ms/step - loss: 0.2432 - accuracy: 0.9223 - val_loss: 0.3369 - val_accuracy: 0.8934\n",
      "Epoch 3/10\n",
      "593/593 [==============================] - 190s 321ms/step - loss: 0.1102 - accuracy: 0.9664 - val_loss: 0.3795 - val_accuracy: 0.8950\n",
      "Epoch 4/10\n",
      "593/593 [==============================] - 197s 332ms/step - loss: 0.0590 - accuracy: 0.9820 - val_loss: 0.4410 - val_accuracy: 0.8927\n",
      "Epoch 5/10\n",
      "593/593 [==============================] - 197s 332ms/step - loss: 0.0345 - accuracy: 0.9901 - val_loss: 0.5477 - val_accuracy: 0.8922\n",
      "Epoch 6/10\n",
      "593/593 [==============================] - 196s 330ms/step - loss: 0.0248 - accuracy: 0.9930 - val_loss: 0.6554 - val_accuracy: 0.8915\n",
      "Epoch 7/10\n",
      "593/593 [==============================] - 193s 326ms/step - loss: 0.0232 - accuracy: 0.9935 - val_loss: 0.6765 - val_accuracy: 0.8934\n",
      "Epoch 8/10\n",
      "593/593 [==============================] - 194s 327ms/step - loss: 0.0236 - accuracy: 0.9937 - val_loss: 0.7900 - val_accuracy: 0.8865\n",
      "Epoch 9/10\n",
      "593/593 [==============================] - 198s 334ms/step - loss: 0.0163 - accuracy: 0.9948 - val_loss: 0.8622 - val_accuracy: 0.8865\n",
      "Epoch 10/10\n",
      "593/593 [==============================] - 195s 329ms/step - loss: 0.0102 - accuracy: 0.9970 - val_loss: 0.8516 - val_accuracy: 0.8909\n",
      "2605/2605 [==============================] - 26s 10ms/step\n",
      "297/297 [==============================] - 3s 10ms/step\n",
      "Validation F1 Score:  0.7935550842742856\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dense, Dropout\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Load the train and test data\n",
    "train_df = pd.read_csv(\"train.csv\")\n",
    "test_df = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# Define the mapping of labels to integers\n",
    "label_to_int = {\n",
    "    0: \"Sci/Tech\",\n",
    "    1: \"Sports\",\n",
    "    2: \"Business\",\n",
    "    3: \"World\",\n",
    "    4: \"Politics\",\n",
    "    5: \"ESG\",\n",
    "    6: \"Health\",\n",
    "    7: \"Entertainment\"\n",
    "}\n",
    "\n",
    "# Tokenize the text data\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_df[\"text\"])\n",
    "\n",
    "# Convert the text data to sequences\n",
    "X = tokenizer.texts_to_sequences(train_df[\"text\"])\n",
    "X = pad_sequences(X, maxlen=500)\n",
    "\n",
    "# Convert the labels to one-hot encoded vectors\n",
    "Y = to_categorical(train_df[\"label\"], num_classes=len(label_to_int))\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=len(tokenizer.word_index)+1, output_dim=100, input_length=500))\n",
    "model.add(Conv1D(filters=64, kernel_size=5, activation=\"relu\"))\n",
    "model.add(MaxPooling1D(pool_size=4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(len(label_to_int), activation=\"softmax\"))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, Y_train, validation_data=(X_val, Y_val), epochs=10, batch_size=64)\n",
    "\n",
    "# Tokenize the test data\n",
    "X_test = tokenizer.texts_to_sequences(test_df[\"text\"])\n",
    "X_test = pad_sequences(X_test, maxlen=500)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Convert the predicted labels to integer format\n",
    "y_pred_int = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Convert the integer labels to their corresponding text labels\n",
    "pred_labels = [label_to_int[i] for i in y_pred_int]\n",
    "\n",
    "# Write the predicted labels to the submission file\n",
    "submission_df = pd.DataFrame({\"id\": test_df[\"id\"], \"label\": pred_labels})\n",
    "submission_df.to_csv(\"submission.csv\", index=False)\n",
    "\n",
    "# Evaluate the model on the validation set using macro f1 score\n",
    "y_val_pred = model.predict(X_val)\n",
    "y_val_pred_int = np.argmax(y_val_pred, axis=1)\n",
    "y_val_true_int = np.argmax(Y_val, axis=1)\n",
    "val_f1_score = f1_score(y_val_true_int, y_val_pred_int, average=\"macro\")\n",
    "print(\"Validation F1 Score: \", val_f1_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3b6a8c-b2b7-444a-8f52-84be625cfa87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c9b652-1ebd-4892-bcf9-0cc0e8b313b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
